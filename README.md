# deeplearning_tutorial

天下无不散之宴席，一起努力了三年的逗比公司终究因为管理经验不足和资金短缺等原因解散了。

为了生计，最近打算去找工作，于是把以前学习的深度学习各种知识再复习和梳理一遍，然后顺便写个相对通俗易懂的教程，希望能给后来者带来一些帮助。

后面就把目录写在这下面吧。

## 思想
这部分因为有很多数学公式，github上没法直接显示，于是放到博客上了。

- [梯度下降和反向传播](https://mikuh.github.io/2017-03-30/%E7%90%86%E8%A7%A3%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD)
- [均方误差、交叉熵、似然估计](https://mikuh.github.io/2019-10-13/%E7%90%86%E8%A7%A3%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE-%E4%BA%A4%E5%8F%89%E7%86%B5-%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1)
- [n-gram及神经网络语言模型](https://mikuh.github.io/2019-10-17/%E7%90%86%E8%A7%A3ngram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B)


## TensorFlow2.0

- [Docker GPU版本环境搭建和安装](https://github.com/mikuh/deeplearning_tutorial/blob/master/TensorFlow2.0/install.md)

