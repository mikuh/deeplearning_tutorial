# 理解最小化均方误差、最小化交叉熵、最大似然估计

简单的讲，在深度学习中，我们希望训练之后的模型对输入$x$的输出$a$尽可能的和真实标签$y$接近。

要比较两个值的大小之前的差异，最简单想法就是求比值或者求差的绝对值，如果是比值的话就是越接近于1两个数值越接近，相减求差绝对值的话，就是越接近于0越接近。

这里的最小化均方误差其实就是类似于求差值的方法，均方误差越小，两个值的差距就越小。这很容易想到，然后我们可以用梯度下降来求

