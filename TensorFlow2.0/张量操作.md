### Tensors
张量是一个多维数组，类似于Numpy `ndarray`对象，`tf.Tensor` 具有数据类型和形状，此外，`tf.Tensor`可以驻留在加速器内存中
（如GPU）。TensorFlow提供了丰富的操作库(`tf.add, tf.matmul, tf.linalg` 等等)可以利用和产生`tf.Tensor`。这些操作能自动转
换原生的Python类型。例如：下面展示了加法、求平方、列表求和的运算
```python
print(tf.add(1, 2))  # output:tf.Tensor(3, shape=(), dtype=int32)
print(tf.add([1, 2], [3, 4])) # output:tf.Tensor([4 6], shape=(2,), dtype=int32)
print(tf.square(5)) # output:tf.Tensor(25, shape=(), dtype=int32)
print(tf.reduce_sum([1, 2, 3])) # output:tf.Tensor(6, shape=(), dtype=int32)

print(tf.square(2) + tf.square(3)) # output:tf.Tensor(13, shape=(), dtype=int32)
```
很容易看出，普通的数字和数组都能被转变成张量，python整数类型默认被转为int32。
这个`tf.square` 也可以用于数组，就是会作用在其中每个元素上求平方，很多内置的函数都具备这样的特点，比如
```python
print(tf.square([2, 3])) # output: tf.Tensor([4 9], shape=(2,), dtype=int32)
print(tf.square([[2, 3], [4, 5]])) 
# output: 
# tf.Tensor(
# [[ 4  9]
#  [16 25]], shape=(2, 2), dtype=int32)

```
`tf.reduce_sum`  默认会对所有数组元素求和，当然也可以指定一个轴进行求和，比如
```python
print(tf.reduce_sum([[1, 2, 3],[4, 5, 6]], 1))
# output: tf.Tensor([ 6 15], shape=(2,), dtype=int32)
```
每个`tf.Tensor`都有一个形状和数据类型，
```python
x = tf.matmul([[1]], [[2, 3]])
print(x)
print(x.shape)
print(x.dtype)
```
output:
```shell
tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)
(1, 2)
<dtype: 'int32'>
```
Numpy数组和tf之间的最明显区别在于:张量可以由加速器内存（如GPU、TPU）支持，张量是不可变的。

张量和Numpy `ndarray` 之间的转换是很方便的，因为如果可能的话，张量和数组可以共享底层的内存表示，但是如果张量
驻留在GPU内存的话，这种共享底层就不行了，会涉及到从GPU到CPU内存的拷贝。

```python
import numpy as np

ndarray = np.ones([3, 3])

print("TensorFlow operations convert numpy arrays to Tensors automatically")
tensor = tf.multiply(ndarray, 42)
print(tensor)


print("And NumPy operations convert Tensors to numpy arrays automatically")
print(np.add(tensor, 1))

print("The .numpy() method explicitly converts a Tensor to a numpy array")
print(tensor.numpy())
```

以上代码会如下输出：
```shell
TensorFlow operations convert numpy arrays to Tensors automatically
tf.Tensor(
[[42. 42. 42.]
 [42. 42. 42.]
 [42. 42. 42.]], shape=(3, 3), dtype=float64)
And NumPy operations convert Tensors to numpy arrays automatically
[[43. 43. 43.]
 [43. 43. 43.]
 [43. 43. 43.]]
The .numpy() method explicitly converts a Tensor to a numpy array
[[42. 42. 42.]
 [42. 42. 42.]
 [42. 42. 42.]]
```
### GPU 加速
许多TensorFlow操作是使用GPU来加速计算的。在没有任何注释的情况下，TensorFlow会自动决定是使用GPU还是CPU来执行操作——如果必要的话，会复制CPU和GPU内存之间的张量。操作产生的张量通常由执行操作的设备的内存支持，例如:
```python
x = tf.random.uniform([3, 3])

print("Is there a GPU available: "),
print(tf.config.experimental.list_physical_devices("GPU"))

print("Is the Tensor on GPU #0:  "),
print(x.device.endswith('GPU:0'))
```
输出：
```shell
Is there a GPU available: 
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Is the Tensor on GPU #0:  
False
```
在TensorFlow中，可以明确在哪个设备上执行单个操作，如果没有明确指明，就自行决定。
我们可以用`tf.device`显式指定：
```python
import time

def time_matmul(x):
  start = time.time()
  for loop in range(10):
    tf.matmul(x, x)

  result = time.time()-start

  print("10 loops: {:0.2f}ms".format(1000*result))

# Force execution on CPU
print("On CPU:")
with tf.device("CPU:0"):
  x = tf.random.uniform([1000, 1000])
  assert x.device.endswith("CPU:0")
  time_matmul(x)

# Force execution on GPU #0 if available
if tf.config.experimental.list_physical_devices("GPU"):
  print("On GPU:")
  with tf.device("GPU:0"): # Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.
    x = tf.random.uniform([1000, 1000])
    assert x.device.endswith("GPU:0")
    time_matmul(x)
```
输出：
```shell
On CPU:
10 loops: 9.43ms
On GPU:
10 loops: 7.36ms
```

### Datasets
本节使用`tf.data.Dataset` 这个API构建一个管道来给model喂数据。这个API用来从样本构建
高性能的复杂输入管道，这些输入管道将为你的模型提供模型训练及验证的循环。

从原始数据创建Dataset，可以用`Dataset.from_tensors`, `Dataset.from_tensor_slices`
这样的工厂函数来创建数据集，或者使用 `TextLineDataset` or `TFRecordDataset` 从文件中读取对象。有关更多信息，
可以参见 [TensorFlow Dataset guide](https://www.tensorflow.org/guide/datasets#reading_input_data)

